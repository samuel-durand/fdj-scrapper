#!/usr/bin/env node

/**
 * SCRIPT CRON POUR O2SWITCH
 * Ã€ exÃ©cuter automatiquement via les tÃ¢ches cron de cPanel
 * 
 * Ce script :
 * 1. Scrape les rÃ©sultats FDJ avec Puppeteer
 * 2. Met Ã  jour resultats-cache.json
 * 3. Log les rÃ©sultats pour suivi
 */

import puppeteer from 'puppeteer';
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// Configuration
const CACHE_FILE = path.join(__dirname, 'resultats-cache.json');
const LOG_FILE = path.join(__dirname, 'cron-logs.txt');

// Fonction de logging
function log(message) {
  const timestamp = new Date().toISOString();
  const logMessage = `[${timestamp}] ${message}\n`;
  
  // Console
  console.log(logMessage.trim());
  
  // Fichier de log
  try {
    fs.appendFileSync(LOG_FILE, logMessage);
  } catch (err) {
    console.error('Erreur lors de l\'Ã©criture du log:', err);
  }
}

// Import du scraper existant
async function runScraper() {
  log('ğŸš€ DÃ©marrage du scraping automatique...');
  
  try {
    // Importer dynamiquement votre scraper
    const scraperPath = path.join(__dirname, 'scraper-urls-directes.js');
    
    log('ğŸ“Š Lancement du scraper...');
    
    // ExÃ©cuter le scraper (0.5 mois = rÃ©sultats rÃ©cents)
    // Votre scraper gÃ©nÃ¨re dÃ©jÃ  resultats-cache.json
    const { execSync } = await import('child_process');
    execSync(`node "${scraperPath}" 0.5`, { 
      cwd: __dirname,
      stdio: 'inherit'
    });
    
    log('âœ… Scraping terminÃ© avec succÃ¨s');
    
    // VÃ©rifier que le fichier existe et a une taille correcte
    if (fs.existsSync(CACHE_FILE)) {
      const stats = fs.statSync(CACHE_FILE);
      const sizeMB = (stats.size / 1024 / 1024).toFixed(2);
      log(`ğŸ“ Fichier gÃ©nÃ©rÃ© : ${sizeMB} MB`);
      
      if (stats.size > 1000) {
        log('âœ… Fichier valide et prÃªt');
        return true;
      } else {
        log('âš ï¸ Fichier trop petit, possible erreur');
        return false;
      }
    } else {
      log('âŒ Fichier cache non gÃ©nÃ©rÃ©');
      return false;
    }
    
  } catch (error) {
    log(`âŒ Erreur lors du scraping : ${error.message}`);
    log(`ğŸ“‹ Stack trace : ${error.stack}`);
    return false;
  }
}

// Fonction principale
async function main() {
  log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  log('ğŸ° CRON JOB O2SWITCH - Mise Ã  jour rÃ©sultats FDJ');
  log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  
  const startTime = Date.now();
  
  const success = await runScraper();
  
  const duration = ((Date.now() - startTime) / 1000).toFixed(2);
  log(`â±ï¸ DurÃ©e totale : ${duration} secondes`);
  
  if (success) {
    log('âœ… TÃ¢che cron terminÃ©e avec succÃ¨s');
    log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
    process.exit(0);
  } else {
    log('âŒ TÃ¢che cron terminÃ©e avec erreurs');
    log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
    process.exit(1);
  }
}

// Lancer le script
main().catch(error => {
  log(`âŒ Erreur fatale : ${error.message}`);
  process.exit(1);
});

